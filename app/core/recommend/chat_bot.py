import json
from app.utils.logger import setup_logger
import re
from langchain_openai import ChatOpenAI
from langchain.retrievers.multi_query import MultiQueryRetriever

logger = setup_logger()

class AgentExecutionError(Exception):
    pass

class LLMAgentService:
    async def run_agent_flow(self, user_input: str, llm_client, conversation_history: list, system_message: str, financial_dict_retriever) -> tuple[str, bool]:
        """
        LLMì„ í˜¸ì¶œí•˜ì—¬ ì‚¬ìš©ìì˜ ì…ë ¥ì— ëŒ€í•œ ì‘ë‹µê³¼ ìƒíƒœë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.
        """
        rag_context = "ì œê³µëœ ì°¸ê³  ì •ë³´ ì—†ìŒ."
        if financial_dict_retriever:
            try:
                llm_for_retriever = ChatOpenAI(
                    model_name="gpt-4o-mini",
                    max_tokens=500,
                    temperature=0,
                    api_key=llm_client.api_key
                )
                multi_query_retriever = MultiQueryRetriever.from_llm(
                    retriever=financial_dict_retriever, # ê¸°ì¡´ ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ê·¸ëŒ€ë¡œ í™œìš©
                    llm=llm_for_retriever # ì§ˆë¬¸ ìƒì„±ì„ ìœ„í•œ LLM
                )
                retrieved_docs = multi_query_retriever.get_relevant_documents(query=user_input)
                if retrieved_docs:
                    # 2. ê²€ìƒ‰ëœ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ì¢‹ì€ í˜•íƒœë¡œ ê°€ê³µí•©ë‹ˆë‹¤.
                    context_lines = []
                    for doc in retrieved_docs:
                        # ì˜ˆì‹œ: "ìš©ì–´: ETF, ì„¤ëª…: ..., ê´€ë ¨ ìŠ¬ë¡¯: ..."
                        # Documentì˜ page_contentë‚˜ metadata êµ¬ì¡°ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.
                        context_lines.append(doc.page_content) 
                    rag_context = "\n---\n".join(context_lines)
            
            except Exception as e:
                logger.error(f"Glossary RAG retrieval failed: {e}", exc_info=True)
                rag_context = "ì°¸ê³  ì •ë³´ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ."   
        CONVERSATIONAL_GUIDELINES = f"""
            [ì—­í• ]
            ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì¬ì • ëª©í‘œ ë‹¬ì„±ì„ ë•ëŠ” ì¹œì ˆí•˜ê³  ìŠ¤ë§ˆíŠ¸í•œ ì „ë¬¸ ê¸ˆìœµ ì–´ë“œë°”ì´ì € 'í† ë¦¬'ì…ë‹ˆë‹¤.
            ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í†µí•´ ì‚¬ìš©ìì˜ ìƒí™©ì„ íŒŒì•…í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œ ë§ì¶¤í˜• ê¸ˆìœµ ì •ë³´ë¥¼ ì¶”ì²œí•˜ê¸° ìœ„í•´ í•„ìš”í•œ í•µì‹¬ ì •ë³´ë“¤ì„ ìˆ˜ì§‘í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
            
            [ìˆ˜ì§‘ ëª©í‘œ ì •ë³´ (Slots)]
            ë‹¹ì‹ ì€ ëŒ€í™”ë¥¼ í†µí•´ ì•„ë˜ 5ê°€ì§€ ì •ë³´ë¥¼ ë°˜ë“œì‹œ íŒŒì•…í•´ì•¼ í•©ë‹ˆë‹¤.
            1. ê´€ì‹¬ ë¶„ì•¼: (ì£¼ì‹, ë¶€ë™ì‚°, ì €ì¶•, í€ë“œ, ì±„ë¬´ ê´€ë¦¬, ê¸ˆìœµì‚¬ê¸°, ëŒ€ì¶œ ë“±)
            2. ìµœì¢… ëª©í‘œ: (ë‚´ì§‘ë§ˆë ¨, ë…¸í›„ì¤€ë¹„, ëª©ëˆë§ˆë ¨ ë“±)
            3. ëª©í‘œ ê¸ˆì•¡: (êµ¬ì²´ì ì¸ ì•¡ìˆ˜)
            4. íˆ¬ì ê²½í—˜: (ì´ˆë³´, ê²½í—˜ì ë“±)
            5. ëª©í‘œ ê¸°ê°„: (ë‹¨ê¸°, ì¤‘ê¸°, ì¥ê¸° ë˜ëŠ” êµ¬ì²´ì ì¸ ê¸°ê°„)
            
            [ëŒ€í™” ì „ëµ]
            - **ëª¨ë“  íŒë‹¨ì€ íƒœê·¸ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.** ë‹µë³€ ë¬¸ì¥ì€ ë”°ë¡œ ìƒì„±í•˜ì§€ ì•Šê³ , ì½”ë“œê°€ ë³„ë„ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            - ì‚¬ìš©ìì˜ ë‹µë³€ì´ ê¸°ì¡´ ì •ë³´ë¥¼ ë” êµ¬ì²´í™”í•˜ëŠ” ê²½ìš°, ì•„ë˜ ì˜ˆì‹œì™€ ì™„ì „íˆ ë™ì¼í•œ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
            âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:
            [ì—…ë°ì´íŠ¸: {{"ê´€ì‹¬ ë¶„ì•¼": "ì£¼ì‹"}}]
            [ì—…ë°ì´íŠ¸: {{"ëª©í‘œ ê¸ˆì•¡": "5000ë§Œì›"}}]

            âŒ ì˜ëª»ëœ ì˜ˆì‹œ:
            [ì—…ë°ì´íŠ¸: {{'"ê´€ì‹¬ ë¶„ì•¼"': 'ì£¼ì‹'}}]
            [ì—…ë°ì´íŠ¸: {{"'ëª©í‘œ ê¸ˆì•¡'": "5000ë§Œì›"}}]
            
            - key ì´ë¦„ì€ ë°˜ë“œì‹œ ìœ„ 5ê°œ ìŠ¬ë¡¯ëª… ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•˜ë©°, ê²¹ë”°ì˜´í‘œë¥¼ ë„£ì§€ ë§ˆì„¸ìš”.
            - í•­ìƒ keyì™€ valueëŠ” í°ë”°ì˜´í‘œ í•œ ë²ˆë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
            
            - ëª¨ë“  ì •ë³´ê°€ ìˆ˜ì§‘ë˜ë©´, **[ì •ë³´ì™„ë£Œ]** íƒœê·¸ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
            - ê¸ˆìœµ, ì¬í…Œí¬ì™€ ë¬´ê´€í•œ ì§ˆë¬¸ì´ë©´ **[ê¸ˆìœµë¬´ê´€]** íƒœê·¸ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
            - ê·¸ ì™¸ì˜ ê²½ìš°, í•„ìš”í•œ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ 2~3ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”.
            
            ---
            [ì°¸ê³  ì •ë³´]
            ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ë°œì–¸ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ê¸ˆìœµ ìš©ì–´ ì •ë³´ì…ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë” ì •í™•í•˜ê²Œ ë¶„ë¥˜í•˜ê³ , í•´ë‹¹í•˜ëŠ” ìŠ¬ë¡¯ ê°’ì„ ì¶”ì¶œí•˜ì„¸ìš”.
            {rag_context}
            ---

            [ì œì•½ ì¡°ê±´]
            - ë‹µë³€ì— [íƒœê·¸]ê°€ í¬í•¨ëœ ê²½ìš°, ë‹¤ë¥¸ ë¬¸ì¥ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
            - JSON íƒœê·¸ ë‚´ keyì™€ valueëŠ” ë°˜ë“œì‹œ í°ë”°ì˜´í‘œ(")ë¥¼ í•œ ë²ˆë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
            - JSON íƒœê·¸ ë’¤ì—ëŠ” ë‹¤ë¥¸ ë¬¸ì¥ì„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”. íƒœê·¸ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
            - ë‹¹ì‹ ì˜ ì‘ë‹µì€ ë°˜ë“œì‹œ [ì—…ë°ì´íŠ¸: {...}], [ì •ë³´ì™„ë£Œ], [ê¸ˆìœµë¬´ê´€] íƒœê·¸ ì¤‘ í•˜ë‚˜ì´ê±°ë‚˜, ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ ì§ˆë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ ì™¸ì˜ ë‹¤ë¥¸ í˜•ì‹(ì˜ˆ: íƒœê·¸ ì—†ëŠ” JSON)ì˜ ì‘ë‹µì€ ì ˆëŒ€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

            [ì‚¬ìš©ì ì…ë ¥]
            {user_input}

            [í† ë¦¬ì˜ ë‹¤ìŒ í–‰ë™ íŒë‹¨]
        """

        messages = [{"role": "system", "content": f"{system_message}\n{CONVERSATIONAL_GUIDELINES}"}]
        messages.extend(conversation_history)  # [{"role": "user"/"assistant", "content": "..."}]
        messages.append({"role": "user", "content": user_input})
        try:
            response_from_llm = llm_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                top_p=0.95, 
                max_tokens=512, 
                temperature=0.2, 
                )
            llm_output = response_from_llm.choices[0].message.content.strip()
            
            # LLMì˜ ì‘ë‹µì— ë”°ë¼ ë¶„ê¸° ì²˜ë¦¬
            if "[ì •ë³´ì™„ë£Œ]" in llm_output:
                return ("final_response_needed", True)
            
            elif "[ê¸ˆìœµë¬´ê´€]" in llm_output:
                return ("irrelevant", False)
            
            elif "[ì—…ë°ì´íŠ¸:" in llm_output:
                try:
                    update_data_match = re.search(r'\[ì—…ë°ì´íŠ¸:\s*(\{.*?\})\]', llm_output)
                    if update_data_match:
                        raw_json = update_data_match.group(1)

                        # ğŸš¨ ì—¬ê¸°ì„œ key ì´ë¦„ ì•ë’¤ì˜ ë”°ì˜´í‘œ ì œê±°
                        # ex) {"'ê´€ì‹¬ ë¶„ì•¼'": "ì£¼ì‹"}  -> {"ê´€ì‹¬ ë¶„ì•¼": "ì£¼ì‹"}
                        cleaned_json = re.sub(r"'([ê°€-í£\s]+)'(?=\s*:)", r'"\1"', raw_json)  # keyì— ì‘ì€ë”°ì˜´í‘œ â†’ í°ë”°ì˜´í‘œ
                        cleaned_json = re.sub(r'"{2,}([ê°€-í£\s]+)"{2,}(?=\s*:)', r'"\1"', cleaned_json)  # ê²¹ë”°ì˜´í‘œ â†’ í•˜ë‚˜ë¡œ
                        logger.info(f"íŒŒì‹± ì „ {cleaned_json}")
                        update_data = json.loads(cleaned_json)
                        logger.info(f"íŒŒì‹± í›„ {update_data}")
                        return (json.dumps({"update": update_data}, ensure_ascii=False), False)
                    else:
                        logger.error(f"ì—…ë°ì´íŠ¸ ì •ê·œì‹ ë§¤ì¹­ ì‹¤íŒ¨. LLM ì¶œë ¥: {llm_output}")
                        logger.info("ì—…ë°ì´íŠ¸ ë¶€ë¶„ ì˜¤ë¥˜")
                        return ("ì±—ë´‡ ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", False)
                except (json.JSONDecodeError, IndexError) as e:
                    logger.error(f"ì—…ë°ì´íŠ¸ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}", exc_info=True)
                    return (llm_output, False)
            else:
                # ì¼ë°˜ì ì¸ ëŒ€í™” (ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ ì§ˆë¬¸)
                return (llm_output, False)
        
        except Exception as e:
            logger.error(f"í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜: {e}", exc_info=True)
            return ("ì±—ë´‡ ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", False)